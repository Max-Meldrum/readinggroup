The choice for all these papers are finding ways to explain deep neural networks decision. What they all have in common is that they do not try to use the black-box approaches to explain the neural network like in LIME or SHAP papers but they rely on transparent and really interpretable methods to explain the decisions of a neural network. All papers are recent and they can be used as a measure of state of the art approaches on explainability of neural networks.
