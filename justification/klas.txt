Stream processing frameworks model computation as a directed acyclic graph of sources, sinks, channels, and operators, commonly referred to as a dataflow graph. Engines may execute dataflow graphs by mapping the computation of each operator to a physical machine in a cluster. For a stream processor to be deterministic, the core requirement is that any element of data which flows through the graph must be processed *exactly-once* by each operator it passes through. For this seminar, the aim is to explore how different production-grade stream processors (Spark Structured Streaming, Flink, and IBM-Streams) achieve *exactly-once* semantics, and investigate possible tradeoffs. The ultimate goal of my PhD is to develop a next-generation stream processor. Therefore, the motivation behind selecting this topic is to discover new facets of stream processing that I can apply to my own research.
